# L11. Domain Adaptation

>   [ML 2022 Spring (ntu.edu.tw)](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)
>
>   https://www.bilibili.com/video/BV1VN4y1P7Zj
>
>   [【《2021机器学习-李宏毅》学习笔记】_李宏毅机器学习2021github-CSDN博客](https://blog.csdn.net/chh13502/article/details/121210730)

[TOC]

当训练数据和测试数据分布不同，会产生不同的效果

![image-20240910133724162](./L11.assets/image-20240910133724162.png)

`Domain shift`：测试数据和训练数据有不同的分布

-   输入分布
-   输出分布
-   输入和输出对应的关系
    -   同一张图片，不同的标签

本章只解决输入分布不同的问题

>   当手上有大量target data时，直接使用target data部分进行训练，不需要做Domain Adaptation
>
>   只有少量时，我们先用source data训练，再用target data微调
>
>   不要在少量的target data上跑过多次迭代，防止过拟合

对于真实环境，我们用source data，和一些无标注的target data

<br />

## Basic Idea

对于手写数字识别这个任务，我们可考虑让模型忽略颜色的feature

target data就可以直接套用source data的模型

![image-20240910134338697](./L11.assets/image-20240910134338697.png)

<br />



## Domain Adversarial Training

![image-20240910135759100](./L11.assets/image-20240910135759100.png)



-   为了完成剔除颜色特征的任务，我们希望我们抽出来的向量的分布是相似的

<br />

![image-20240910135625650](./L11.assets/image-20240910135625650.png)

-   引入GAN的思想

-   但是问题可能会出在Discriminator上，其最后故意判错，我们无法让Generator生成相似的分布
-   但实际上其实效果还是不错的

<br />



## Decision Boundary

![image-20240910140604509](./L11.assets/image-20240910140604509.png)

-   从boundary的角度解释，显然右边这种分布会更好
-   无标签的分布远离boundary，尽可能集中在某一个类别上，对于domain adaptation会更加轻松

![image-20240910140735419](./L11.assets/image-20240910140735419.png)

实际上就是让概率分布集中一点

<br />



## Universal Domain Adaptation

![image-20240910140956581](./L11.assets/image-20240910140956581.png)

事实上我们不总是让source和target有相似的distribution

target是无标签的，两者可能有交集、互相包含



## 省流

-   target没有label、只有一份：Testing Time Training
-   完全没有target：Domain Generalization
    -   训练数据的domain非常丰富
    -   训练数据只有一个domain，测试数据domain多

![image-20240910141908598](./L11.assets/image-20240910141908598.png)

只给出了论文链接





![image-20240910141645028](./L11.assets/image-20240910141645028.png)
