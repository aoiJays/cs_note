# L5. Sequence to Sequence

>   [ML 2022 Spring (ntu.edu.tw)](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)
>
>   https://www.bilibili.com/video/BV1VN4y1P7Zj

[TOC]

输出的长度取决于model

-   Speech Recognition：语音到文本
-   Machine Translation：文本到文本
-   Speech Translation：语音到文本



-   Seq2Seq = encoder + decoder
    -   encoder：输入->向量
    -   decoder：向量->输出
        -   接受encoder的输入，每次输出一个结果，输出的结果会影响下一个输出
        -   加入`<BOS>`表示开始解码，`<EOS>`表示结束



## Transformer - Encoder

### Block

Encoder内以block为单位

每个block的设计：

![image-20240811211637233](./L5.assets/image-20240811211637233.png)

### Encoder

![image-20240811212043472](./L5.assets/image-20240811212043472.png)

-   输入需要Position Embedding
-   重复N次block

>   这是原始的Transformer结构
>
>   后续发现把LayerNorm放在Attention前和FC前，效果会更好



