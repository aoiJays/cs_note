{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../Dataset', train=True, transform=torchvision.transforms.ToTensor(), download=True) # 训练集\n",
    "test_set = torchvision.datasets.CIFAR10(root='../Dataset', train=False, transform=torchvision.transforms.ToTensor(), download=True) # 测试集\n",
    "\n",
    "train_data_size = len(train_set)\n",
    "test_data_size = len(test_set)\n",
    "\n",
    "print(train_data_size, test_data_size)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mynn(nn.Module):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.sequential = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),\n",
    "\t\t\tnn.MaxPool2d(2),\n",
    "\t\t\tnn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2),\n",
    "\t\t\tnn.MaxPool2d(2),\n",
    "\t\t\tnn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "\t\t\tnn.MaxPool2d(2),\n",
    "\t\t\tnn.Flatten(), # 将tensor张成一维张量\n",
    "\t\t\tnn.Linear(1024, 64),\n",
    "\t\t\tnn.Linear(64, 10)\n",
    "\t\t)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.sequential(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "mynn = Mynn().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optim = optim.SGD(mynn.parameters(), lr = 1e-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------第1轮训练-------------\n",
      "16000/50000 Loss = 2.2700324058532715\n",
      "32000/50000 Loss = 2.058711051940918\n",
      "48000/50000 Loss = 1.9346328973770142\n",
      "测试集Loss = 0.030688621509075163\n",
      "-----------第2轮训练-------------\n",
      "16000/50000 Loss = 1.9693937301635742\n",
      "32000/50000 Loss = 1.8067421913146973\n",
      "48000/50000 Loss = 1.539539098739624\n",
      "测试集Loss = 0.028251412725448607\n",
      "-----------第3轮训练-------------\n",
      "16000/50000 Loss = 1.6046457290649414\n",
      "32000/50000 Loss = 1.8275642395019531\n",
      "48000/50000 Loss = 1.5761982202529907\n",
      "测试集Loss = 0.027140550899505615\n",
      "-----------第4轮训练-------------\n",
      "16000/50000 Loss = 1.6657586097717285\n",
      "32000/50000 Loss = 1.3916832208633423\n",
      "48000/50000 Loss = 1.6195838451385498\n",
      "测试集Loss = 0.024627774798870086\n",
      "-----------第5轮训练-------------\n",
      "16000/50000 Loss = 1.3789002895355225\n",
      "32000/50000 Loss = 1.5630862712860107\n",
      "48000/50000 Loss = 1.3996326923370361\n",
      "测试集Loss = 0.02398908793926239\n",
      "-----------第6轮训练-------------\n",
      "16000/50000 Loss = 1.2628931999206543\n",
      "32000/50000 Loss = 1.293960690498352\n",
      "48000/50000 Loss = 1.3363863229751587\n",
      "测试集Loss = 0.021812228417396544\n",
      "-----------第7轮训练-------------\n",
      "16000/50000 Loss = 1.3201384544372559\n",
      "32000/50000 Loss = 1.2697429656982422\n",
      "48000/50000 Loss = 1.4025261402130127\n",
      "测试集Loss = 0.02179011160135269\n",
      "-----------第8轮训练-------------\n",
      "16000/50000 Loss = 1.2192579507827759\n",
      "32000/50000 Loss = 1.3175007104873657\n",
      "48000/50000 Loss = 1.3213118314743042\n",
      "测试集Loss = 0.021053267693519593\n",
      "-----------第9轮训练-------------\n",
      "16000/50000 Loss = 0.9379936456680298\n",
      "32000/50000 Loss = 1.4752326011657715\n",
      "48000/50000 Loss = 1.3190945386886597\n",
      "测试集Loss = 0.02096406887769699\n",
      "-----------第10轮训练-------------\n",
      "16000/50000 Loss = 1.263115406036377\n",
      "32000/50000 Loss = 1.1379098892211914\n",
      "48000/50000 Loss = 1.345162272453308\n",
      "测试集Loss = 0.025165993797779083\n",
      "-----------第11轮训练-------------\n",
      "16000/50000 Loss = 1.1882004737854004\n",
      "32000/50000 Loss = 1.2259701490402222\n",
      "48000/50000 Loss = 1.2824729681015015\n",
      "测试集Loss = 0.019092207652330398\n",
      "-----------第12轮训练-------------\n",
      "16000/50000 Loss = 1.0455135107040405\n",
      "32000/50000 Loss = 1.1009314060211182\n",
      "48000/50000 Loss = 1.0285851955413818\n",
      "测试集Loss = 0.017721649610996246\n",
      "-----------第13轮训练-------------\n",
      "16000/50000 Loss = 0.95150226354599\n",
      "32000/50000 Loss = 0.8859463930130005\n",
      "48000/50000 Loss = 0.8514403104782104\n",
      "测试集Loss = 0.017084768825769425\n",
      "-----------第14轮训练-------------\n",
      "16000/50000 Loss = 1.0640290975570679\n",
      "32000/50000 Loss = 0.8889973163604736\n",
      "48000/50000 Loss = 1.168245792388916\n",
      "测试集Loss = 0.01738684357404709\n",
      "-----------第15轮训练-------------\n",
      "16000/50000 Loss = 1.1330227851867676\n",
      "32000/50000 Loss = 0.7697573900222778\n",
      "48000/50000 Loss = 0.7170059084892273\n",
      "测试集Loss = 0.016702828752994538\n",
      "-----------第16轮训练-------------\n",
      "16000/50000 Loss = 0.9782381057739258\n",
      "32000/50000 Loss = 0.8317427635192871\n",
      "48000/50000 Loss = 0.8421778678894043\n",
      "测试集Loss = 0.01639626296162605\n",
      "-----------第17轮训练-------------\n",
      "16000/50000 Loss = 0.8387510776519775\n",
      "32000/50000 Loss = 0.8734027147293091\n",
      "48000/50000 Loss = 0.9114200472831726\n",
      "测试集Loss = 0.023765496397018433\n",
      "-----------第18轮训练-------------\n",
      "16000/50000 Loss = 0.7804050445556641\n",
      "32000/50000 Loss = 0.8097693920135498\n",
      "48000/50000 Loss = 0.6719220280647278\n",
      "测试集Loss = 0.016066960567235947\n",
      "-----------第19轮训练-------------\n",
      "16000/50000 Loss = 0.956012487411499\n",
      "32000/50000 Loss = 0.6035057306289673\n",
      "48000/50000 Loss = 1.2093946933746338\n",
      "测试集Loss = 0.015986972630023955\n",
      "-----------第20轮训练-------------\n",
      "16000/50000 Loss = 0.8978260159492493\n",
      "32000/50000 Loss = 0.6158565282821655\n",
      "48000/50000 Loss = 1.172896146774292\n",
      "测试集Loss = 0.016478612762689592\n",
      "-----------第21轮训练-------------\n",
      "16000/50000 Loss = 0.6177759170532227\n",
      "32000/50000 Loss = 0.8851650953292847\n",
      "48000/50000 Loss = 0.7597873210906982\n",
      "测试集Loss = 0.01871211044192314\n",
      "-----------第22轮训练-------------\n",
      "16000/50000 Loss = 0.8212072253227234\n",
      "32000/50000 Loss = 0.9024287462234497\n",
      "48000/50000 Loss = 0.7749155759811401\n",
      "测试集Loss = 0.015804619210958482\n",
      "-----------第23轮训练-------------\n",
      "16000/50000 Loss = 0.6425222158432007\n",
      "32000/50000 Loss = 0.6637999415397644\n",
      "48000/50000 Loss = 0.5704911351203918\n",
      "测试集Loss = 0.01764690898656845\n",
      "-----------第24轮训练-------------\n",
      "16000/50000 Loss = 0.93402498960495\n",
      "32000/50000 Loss = 0.7421050667762756\n",
      "48000/50000 Loss = 0.6900208592414856\n",
      "测试集Loss = 0.017250832414627076\n",
      "-----------第25轮训练-------------\n",
      "16000/50000 Loss = 0.7806307077407837\n",
      "32000/50000 Loss = 0.9759928584098816\n",
      "48000/50000 Loss = 0.7545499205589294\n",
      "测试集Loss = 0.017040030282735825\n",
      "-----------第26轮训练-------------\n",
      "16000/50000 Loss = 0.6064941883087158\n",
      "32000/50000 Loss = 0.9634947776794434\n",
      "48000/50000 Loss = 0.6507030129432678\n",
      "测试集Loss = 0.015849862307310104\n",
      "-----------第27轮训练-------------\n",
      "16000/50000 Loss = 0.762700080871582\n",
      "32000/50000 Loss = 0.7638620734214783\n",
      "48000/50000 Loss = 0.6733358502388\n",
      "测试集Loss = 0.016748720037937165\n",
      "-----------第28轮训练-------------\n",
      "16000/50000 Loss = 0.5324517488479614\n",
      "32000/50000 Loss = 0.7707423567771912\n",
      "48000/50000 Loss = 0.7781458497047424\n",
      "测试集Loss = 0.01528647980093956\n",
      "-----------第29轮训练-------------\n",
      "16000/50000 Loss = 0.48158466815948486\n",
      "32000/50000 Loss = 0.7098115682601929\n",
      "48000/50000 Loss = 0.6841444969177246\n",
      "测试集Loss = 0.01663600240945816\n",
      "-----------第30轮训练-------------\n",
      "16000/50000 Loss = 0.5648974180221558\n",
      "32000/50000 Loss = 0.6516777873039246\n",
      "48000/50000 Loss = 0.660645067691803\n",
      "测试集Loss = 0.016863643079996108\n",
      "-----------第31轮训练-------------\n",
      "16000/50000 Loss = 0.49097952246665955\n",
      "32000/50000 Loss = 0.6689440608024597\n",
      "48000/50000 Loss = 0.5782026052474976\n",
      "测试集Loss = 0.018566634324193\n",
      "-----------第32轮训练-------------\n",
      "16000/50000 Loss = 0.48509612679481506\n",
      "32000/50000 Loss = 0.6498083472251892\n",
      "48000/50000 Loss = 0.4905472993850708\n",
      "测试集Loss = 0.016621671652793886\n",
      "-----------第33轮训练-------------\n",
      "16000/50000 Loss = 0.47137004137039185\n",
      "32000/50000 Loss = 0.5829017162322998\n",
      "48000/50000 Loss = 0.6457129120826721\n",
      "测试集Loss = 0.017632281923294066\n",
      "-----------第34轮训练-------------\n",
      "16000/50000 Loss = 0.5874856114387512\n",
      "32000/50000 Loss = 0.5170104503631592\n",
      "48000/50000 Loss = 0.5833978056907654\n",
      "测试集Loss = 0.017409734413027764\n",
      "-----------第35轮训练-------------\n",
      "16000/50000 Loss = 0.40703198313713074\n",
      "32000/50000 Loss = 0.5236727595329285\n",
      "48000/50000 Loss = 0.4112519323825836\n",
      "测试集Loss = 0.017998510509729386\n",
      "-----------第36轮训练-------------\n",
      "16000/50000 Loss = 0.4309442341327667\n",
      "32000/50000 Loss = 0.43548744916915894\n",
      "48000/50000 Loss = 0.5616444945335388\n",
      "测试集Loss = 0.018857041370868684\n",
      "-----------第37轮训练-------------\n",
      "16000/50000 Loss = 0.4104636013507843\n",
      "32000/50000 Loss = 0.7480686902999878\n",
      "48000/50000 Loss = 0.7323380708694458\n",
      "测试集Loss = 0.017048946970701216\n",
      "-----------第38轮训练-------------\n",
      "16000/50000 Loss = 0.6512799859046936\n",
      "32000/50000 Loss = 0.3615562617778778\n",
      "48000/50000 Loss = 0.459106981754303\n",
      "测试集Loss = 0.021400569385290145\n",
      "-----------第39轮训练-------------\n",
      "16000/50000 Loss = 0.4731382727622986\n",
      "32000/50000 Loss = 0.4149446487426758\n",
      "48000/50000 Loss = 0.3368847668170929\n",
      "测试集Loss = 0.01958644729554653\n",
      "-----------第40轮训练-------------\n",
      "16000/50000 Loss = 0.36641624569892883\n",
      "32000/50000 Loss = 0.4806087911128998\n",
      "48000/50000 Loss = 0.3545188009738922\n",
      "测试集Loss = 0.018975463846325875\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\") # 创建对象 在logs文件夹下保存文件\n",
    "\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "\t\n",
    "\tprint('-----------第{}轮训练-------------'.format(i + 1))\n",
    "\t\n",
    "\ttrain_size = 0\t\n",
    "\ttrain_step = 0\n",
    "\n",
    "\tfor imgs, targets in train_loader:\n",
    "\t\t\n",
    "\t\timgs = imgs.to(device)\n",
    "\t\ttargets = targets.to(device)\n",
    "\n",
    "\t\t# 正向推理\n",
    "\t\toutputs = mynn(imgs)\n",
    "\t\tloss = loss_fn(outputs, targets)\n",
    "\t\t\n",
    "\t\t# 优化\n",
    "\t\toptim.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptim.step()\n",
    "\n",
    "\n",
    "\t\t# 观察损失函数\t\n",
    "\t\ttrain_size += len(imgs)\n",
    "\t\ttrain_step += 1\n",
    "\n",
    "\t\twriter.add_scalar(\"Train Loss\", loss.item(), train_step)\n",
    "\t\tif train_step % 250 == 0:\n",
    "\t\t\tprint('{}/{} Loss = {}'.format(train_size, train_data_size, loss.item()))\n",
    "\n",
    "\t\n",
    "\t# 测试\n",
    "\ttotal_loss = 0\n",
    "\n",
    "\t# 上下文管理器：\n",
    "\t# with 语句是一个上下文管理器，确保在其内部的代码块在启用了 torch.no_grad() 模式下执行。\n",
    "\t# 一旦代码块执行完毕，上下文管理器会恢复之前的状态，如果之前启用了梯度计算，则重新启用。\n",
    "\n",
    "\t# torch.no_grad() 纯推理 不需要记录梯度 节省时间\n",
    "\twith torch.no_grad():\n",
    "\t\tfor imgs, targets in test_loader:\n",
    "\n",
    "\t\t\timgs = imgs.to(device)\n",
    "\t\t\ttargets = targets.to(device)\n",
    "\t\t\t\n",
    "\t\t\toutputs = mynn(imgs)\n",
    "\t\t\tloss = loss_fn(outputs, targets)\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\n",
    "\t\twriter.add_scalar(\"Test Loss\", total_loss/test_data_size, i)\n",
    "\t\tprint('测试集Loss = {}'.format(total_loss/test_data_size))\n",
    "\n",
    "\n",
    "\tif (i + 1) % 10 == 0:\n",
    "\t\ttorch.save(mynn, './model/train_model{}.pth'.format(i))\n",
    "\t\n",
    "writer.close()\t \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
