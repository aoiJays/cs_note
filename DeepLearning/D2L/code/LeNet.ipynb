{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.Lenet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5),\n",
    "            nn.BatchNorm2d(120),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84), # 1d\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Lenet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 60000\n",
      "test size = 10000\n"
     ]
    }
   ],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "print( f'train size = {len(train_dataset)}' )\n",
    "print( f'test size = {len(test_dataset)}' )\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "model = LeNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss, correct= 0.0, 0.0\n",
    "    n = 0\n",
    "\n",
    "    for X,y in dataloader:\n",
    "    \n",
    "        X,y = X.to(device), y.to(device)\n",
    "        output = model(X)\n",
    "\n",
    "        cur_loss = loss_fn(output, y)\n",
    "    \n",
    "        _, pred = torch.max(output, axis = 1)\n",
    "        print(output,y,pred,sep='\\n----------\\n')\n",
    "        break\n",
    "        optimizer.zero_grad()\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += cur_loss * len(y)\n",
    "        correct += torch.sum(pred==y).item()\n",
    "        n += len(y)\n",
    "    return loss / n, correct / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(dataloader, model, loss_fn):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        loss, correct= 0.0, 0.0\n",
    "        n = 0 \n",
    "\n",
    "        for X,y in dataloader:\n",
    "\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            _, pred = torch.max(output, axis = 1)\n",
    "            \n",
    "            cur_loss = loss_fn(output, y)\n",
    "            correct += torch.sum(pred==y).item()\n",
    "            loss += cur_loss * len(y)\n",
    "            n += len(y)\n",
    "            \n",
    "    return loss/n, correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1656e+00,  9.2382e-03,  1.3240e+00, -4.0105e-01,  8.0792e-02,\n",
      "         -3.3268e-02, -2.3275e-01, -4.3888e-01, -4.3683e-01,  4.2631e-01],\n",
      "        [ 1.3845e-01,  6.8420e-01, -7.3093e-01,  7.8701e-04, -7.4541e-01,\n",
      "          8.9024e-02, -4.5218e-01,  5.6884e-02,  5.2930e-01,  4.0540e-01],\n",
      "        [-1.0075e+00,  1.2790e-03,  3.1477e-01, -2.0390e-01,  6.8482e-01,\n",
      "          3.5114e-01,  4.6164e-01, -6.7865e-03, -3.4495e-01, -7.0498e-01],\n",
      "        [-2.8345e-01, -8.4720e-01, -1.0443e+00,  4.5808e-01,  3.7140e-01,\n",
      "         -3.2739e-01,  6.2033e-01,  4.4460e-01,  2.3321e-01, -3.5589e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([7, 7, 3, 9], device='cuda:0')\n",
      "----------\n",
      "tensor([2, 1, 4, 6], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 8\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m acc = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(pred\u001b[38;5;241m==\u001b[39my)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m     n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m, correct \u001b[38;5;241m/\u001b[39m n\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "max_acc = 0\n",
    "\n",
    "params = model.state_dict()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss, acc = training(train_loader, model, loss_fn, optimizer)\n",
    "    print(f'epoch {epoch + 1}/{epochs}: loss = {loss} acc = {acc}')\n",
    "    break\n",
    "    loss, acc = val(test_loader, model, loss_fn)\n",
    "    print(f'Validation: loss = {loss} acc = {acc}\\n')\n",
    "\n",
    "    # if acc > max_acc:\n",
    "    #     max_acc = acc\n",
    "    #     params = model.state_dict()\n",
    "    #     print('saved local best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6871)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[ 1.1656e+00,  9.2382e-03,  1.3240e+00, -4.0105e-01,  8.0792e-02,\n",
    "         -3.3268e-02, -2.3275e-01, -4.3888e-01, -4.3683e-01,  4.2631e-01],\n",
    "        [ 1.3845e-01,  6.8420e-01, -7.3093e-01,  7.8701e-04, -7.4541e-01,\n",
    "          8.9024e-02, -4.5218e-01,  5.6884e-02,  5.2930e-01,  4.0540e-01],\n",
    "        [-1.0075e+00,  1.2790e-03,  3.1477e-01, -2.0390e-01,  6.8482e-01,\n",
    "          3.5114e-01,  4.6164e-01, -6.7865e-03, -3.4495e-01, -7.0498e-01],\n",
    "        [-2.8345e-01, -8.4720e-01, -1.0443e+00,  4.5808e-01,  3.7140e-01,\n",
    "         -3.2739e-01,  6.2033e-01,  4.4460e-01,  2.3321e-01, -3.5589e-01]]\n",
    "\n",
    "x = torch.tensor(x)\n",
    "fn = nn.CrossEntropyLoss()\n",
    "\n",
    "y = torch.tensor([7, 7, 3, 9])\n",
    "\n",
    "fn(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6871)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = F.one_hot(y, num_classes=10)\n",
    "\n",
    "yy = yy * 1.\n",
    "fn(x,yy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
