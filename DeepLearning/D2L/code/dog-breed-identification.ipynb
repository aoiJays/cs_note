{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_HOST = 1\n",
    "CPU_TEST = 1\n",
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "lr_period = 2\n",
    "lr_decay = 0.9 # 学习率变成原本的0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径\n",
    "if LOCAL_HOST:\n",
    "    train_csv = 'data/dog-breed-identification/labels.csv'\n",
    "    test_csv = 'data/dog-breed-identification/sample_submission.csv'  \n",
    "    train_images_dir = 'data/dog-breed-identification/train/'\n",
    "    test_images_dir = 'data/dog-breed-identification/test/'\n",
    "else:\n",
    "    train_csv = '/kaggle/input/classify-leaves/labels.csv'\n",
    "    test_csv = '/kaggle/input/classify-leaves/sample_submission.csv'  \n",
    "    train_images_dir = '/kaggle/input/classify-leaves/train/'\n",
    "    test_images_dir = '/kaggle/input/classify-leaves/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_csv)\n",
    "categories = pd.unique(train_data['breed']).tolist()\n",
    "categories.sort()\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10357"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, x, y):\n",
    "        self.id_list = x\n",
    "        self.breed = y\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomResizedCrop(224, scale=(0.2, 1.0),\n",
    "                                             ratio=(3.0 / 4.0, 4.0 / 3.0)),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ColorJitter(brightness=0.3, contrast=0.3,\n",
    "                                       saturation=0.3),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.breed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.root_dir + self.id_list[idx] + '.jpg'\n",
    "        image = Image.open(image_name)\n",
    "        return self.transform(image), self.breed[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['breed']\n",
    "train_labels = torch.tensor(pd.get_dummies(train_labels).astype('float32').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177 2045\n"
     ]
    }
   ],
   "source": [
    "base_dataset = dogDataset(train_images_dir, train_data['id'].tolist(), train_labels)\n",
    "train_size = int(0.8 * len(base_dataset))\n",
    "\n",
    "val_size = len(base_dataset) - train_size\n",
    "print(train_size, val_size)\n",
    "\n",
    "train_subset, val_subset = random_split(base_dataset, [train_size, val_size])\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dogDataset(test_images_dir, test_data['id'].tolist(), train_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(base_resnet, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 120)\n",
    "        )\n",
    "        \n",
    "        # 将其他层的参数设置为不需要更新\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.model(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(dataloader, model, loss_fn, optimizer, devices):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for X,y in dataloader:\n",
    "        X,y = X.to(devices[0]), y.to(devices[0])\n",
    "        output = model(X)\n",
    "\n",
    "        cur_loss = loss_fn(output, y)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += cur_loss\n",
    "        n += len(y)\n",
    "\n",
    "    return loss / n\n",
    "\n",
    "def val(dataloader, model, loss_fn, devices):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        loss = 0.0\n",
    "        n = 0 \n",
    "\n",
    "        for X,y in dataloader:\n",
    "\n",
    "            X,y = X.to(devices[0]), y.to(devices[0])\n",
    "            output = model(X)\n",
    "            cur_loss = loss_fn(output, y)\n",
    "            loss += cur_loss \n",
    "            n += len(y)\n",
    "    return loss/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aoijays/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aoijays/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "model = base_resnet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "\n",
    "devices = [device]\n",
    "if device != 'cpu' and torch.cuda.device_count() > 1:\n",
    "    devices = list(range(torch.cuda.device_count()))    \n",
    "    nn.DataParallel(model, device_ids=devices).to(devices[0])\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)\n",
    "\n",
    "epochs = 0\n",
    "min_loss = 1e10\n",
    "params = model.state_dict()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss = training(train_loader, model, loss_fn, optimizer, devices)\n",
    "    print(f'epoch {epoch + 1}/{epochs}: loss = {loss} ')\n",
    "    loss = val(val_loader, model, loss_fn, devices)\n",
    "    print(f'Validation: loss = {loss} \\n')\n",
    "\n",
    "\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        params = model.state_dict()\n",
    "        print('saved local best')\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "        \n",
    "print(min_loss)\n",
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = nn.Softmax()\n",
    "\n",
    "data = []\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for X,y in test_loader:\n",
    "\n",
    "        X = X.to(devices[0])\n",
    "        y_ = model(X)\n",
    "        \n",
    "        for pred in y_:\n",
    "            pred = fun(pred)\n",
    "            pred = pred.to('cpu').tolist()\n",
    "            pred.insert(0,test_data['id'].iloc[cnt] )\n",
    "            cnt+=1\n",
    "            data.append(pred)\n",
    "            # print(pred)\n",
    "\n",
    "        if cnt > 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.insert(0, 'id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'affenpinscher',\n",
       " 'afghan_hound',\n",
       " 'african_hunting_dog',\n",
       " 'airedale',\n",
       " 'american_staffordshire_terrier',\n",
       " 'appenzeller',\n",
       " 'australian_terrier',\n",
       " 'basenji',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'bedlington_terrier',\n",
       " 'bernese_mountain_dog',\n",
       " 'black-and-tan_coonhound',\n",
       " 'blenheim_spaniel',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'border_collie',\n",
       " 'border_terrier',\n",
       " 'borzoi',\n",
       " 'boston_bull',\n",
       " 'bouvier_des_flandres',\n",
       " 'boxer',\n",
       " 'brabancon_griffon',\n",
       " 'briard',\n",
       " 'brittany_spaniel',\n",
       " 'bull_mastiff',\n",
       " 'cairn',\n",
       " 'cardigan',\n",
       " 'chesapeake_bay_retriever',\n",
       " 'chihuahua',\n",
       " 'chow',\n",
       " 'clumber',\n",
       " 'cocker_spaniel',\n",
       " 'collie',\n",
       " 'curly-coated_retriever',\n",
       " 'dandie_dinmont',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'doberman',\n",
       " 'english_foxhound',\n",
       " 'english_setter',\n",
       " 'english_springer',\n",
       " 'entlebucher',\n",
       " 'eskimo_dog',\n",
       " 'flat-coated_retriever',\n",
       " 'french_bulldog',\n",
       " 'german_shepherd',\n",
       " 'german_short-haired_pointer',\n",
       " 'giant_schnauzer',\n",
       " 'golden_retriever',\n",
       " 'gordon_setter',\n",
       " 'great_dane',\n",
       " 'great_pyrenees',\n",
       " 'greater_swiss_mountain_dog',\n",
       " 'groenendael',\n",
       " 'ibizan_hound',\n",
       " 'irish_setter',\n",
       " 'irish_terrier',\n",
       " 'irish_water_spaniel',\n",
       " 'irish_wolfhound',\n",
       " 'italian_greyhound',\n",
       " 'japanese_spaniel',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'kerry_blue_terrier',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'labrador_retriever',\n",
       " 'lakeland_terrier',\n",
       " 'leonberg',\n",
       " 'lhasa',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'maltese_dog',\n",
       " 'mexican_hairless',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'newfoundland',\n",
       " 'norfolk_terrier',\n",
       " 'norwegian_elkhound',\n",
       " 'norwich_terrier',\n",
       " 'old_english_sheepdog',\n",
       " 'otterhound',\n",
       " 'papillon',\n",
       " 'pekinese',\n",
       " 'pembroke',\n",
       " 'pomeranian',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'rhodesian_ridgeback',\n",
       " 'rottweiler',\n",
       " 'saint_bernard',\n",
       " 'saluki',\n",
       " 'samoyed',\n",
       " 'schipperke',\n",
       " 'scotch_terrier',\n",
       " 'scottish_deerhound',\n",
       " 'sealyham_terrier',\n",
       " 'shetland_sheepdog',\n",
       " 'shih-tzu',\n",
       " 'siberian_husky',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'staffordshire_bullterrier',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'sussex_spaniel',\n",
       " 'tibetan_mastiff',\n",
       " 'tibetan_terrier',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'vizsla',\n",
       " 'walker_hound',\n",
       " 'weimaraner',\n",
       " 'welsh_springer_spaniel',\n",
       " 'west_highland_white_terrier',\n",
       " 'whippet',\n",
       " 'wire-haired_fox_terrier',\n",
       " 'yorkshire_terrier']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
