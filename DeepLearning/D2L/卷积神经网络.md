# 卷积神经网络

>   **动手学深度学习v2** - https://www.bilibili.com/video/BV18p4y1h7Dr
>
>   [课程安排 - 动手学深度学习课程 (d2l.ai)](https://courses.d2l.ai/zh-v2/)

[TOC]

## Pytorch补充

有如下代码：

```python
import torch
from torch import nn

class Mynn(nn.Module):

    def __init__(self):
        super().__init__()
        self.sequential1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),
            nn.MaxPool2d(2),
            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2),
            nn.MaxPool2d(2),
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),
            nn.MaxPool2d(2),
            nn.Flatten(), # 将tensor张成一维张量
            nn.Linear(1024, 64),
            nn.Linear(64, 10)
        )
        self.sequential2 = nn.Linear(10,10)
        self.classfication = nn.Sequential(
            nn.Linear(10,10),
            nn.Linear(10,10),
            nn.Linear(10,10)
        )


mynn = Mynn()
print(mynn)

'''
Mynn(
  (sequential1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=1024, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=10, bias=True)
  )
  (sequential2): Linear(in_features=10, out_features=10, bias=True)
  (classfication): Sequential(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
)
'''
```



### 参数管理

-   参数访问：

    -   ```python
        mynn.classfication[0].bias
        mynn.classfication[0].weight
        mynn.classfication[0].state_dict() # 返回指定层权重字典
        
        mynn.classfication[0].weight.grad = None # 也能访问修改梯度
        print(mynn.classfication[0].weight.grad)
        
        # 访问所有参数
        for name, param in mynn.named_parameters(): 
            print(name)
            
        # 访问指定层所有参数
        for name, param in mynn.classfication.named_parameters(): 
            print(name)
        ```

-   权重初始化

    -   ```python
        def xavier(m):
            if type(m) == nn.Linear:
                nn.init.xavier_uniform_(m.weight)
        
        def init_42(m):
            if type(m) == nn.Linear:
                nn.init.constant_(m.weight, 42)
        
        mynn.classfication[0].apply(xavier)
        mynn.classfication[1].apply(init_42)
        
        print(mynn.classfication[0].weight.data)
        print(mynn.classfication[1].weight.data)
        ```

### 读写文件

-   张量的保存

    -   ```python
        x = torch.arange(12.)
        torch.save(x, 'x.temp')
        x2 = torch.load('x.temp')
        print(x2)
        
        # 列表形式
        x,y,z = torch.arange(12.),torch.arange(12.),torch.arange(12.)
        torch.save([x,y,z], 'xyz.temp')
        x2,y2,z2 = torch.load('xyz.temp')
        print(x2,y2,z2,sep='\n')
        
        # 字典形式
        x,y,z = torch.arange(12.),torch.arange(12.),torch.arange(12.)
        
        dict = {
            'x':x, 'y':y, 'z':z
        }
        torch.save(dict, 'xyz.temp')
        
        res =  torch.load('xyz.temp')
        print(res)
        '''
        {'x': tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),
         'y': tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),
         'z': tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])}
         '''
        ```

-   模型参数保存

    -   事实上已经知道如何保存字典了，模型参数能以字典存储

    -   ```python
        torch.save(mynn.state_dict(), 'mynn.pth') # 保存
        new_model = Mynn()
        new_model.load_state_dict(torch.load('mynn.pth')) # 加载
        ```





### GPU管理

```python
print(torch.cuda.device_count()) # 查询gpu数量

x = torch.arange(12., device=torch.device('cpu'))
print(x.device) # cpu

y = torch.arange(12., device=torch.device(f'cuda:{0}'))
print(y.device) # cuda:0

x = x.cuda()
print(x.device) # cuda:0
```



## 卷积神经网络

### 卷积层

